from http.client import HTTPException
from fastapi import APIRouter
from app.models.execute_sql_request import ExecuteRequest
from app.models.query_request import QueryRequest
from app.services.connections import create_connection, get_connections
from app.services.internal_database_service import DatabaseService
from app.services.llm_service import LocalLLMConnector

router = APIRouter(
    prefix="/llmsql",
    tags=["SQL Generation"],
    responses={404: {"description": "Not found"}},
)
llm = LocalLLMConnector(model_name="deepseek-r1", temperature=0.1)
db_service = DatabaseService()


@router.post("/generate_sql")
async def generate_sql(req: QueryRequest):
    """
    Generate SQL from a natural language instruction using the local LLM.
    This endpoint DOES NOT execute the SQL, it only returns it for review.
    """
    llm_response = llm.run(req.user_input)

    sql_code = llm_response.get("sql")
    explanation = llm_response.get("explanation")

    if not sql_code:
        raise HTTPException(status_code=400, detail="No SQL generated by LLM.")

    return {
        "generated_sql": sql_code,
        "explanation": explanation,
        "preview": "Review this SQL before execution.",
    }


@router.post("/execute_sql")
def execute_sql(req: ExecuteRequest):
    """
    Execute a validated or user-approved SQL command on the connected database.
    """
    try:
        result = db_service.execute(req.sql)
        return {"executed_sql": req.sql, "result": result}
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
